{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcvVXX6C5wyO"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Intrinsic Innovation LLC.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrQCQyMyspeJ"
      },
      "source": [
        "[Restricted Boltzmann Machine (RBM)](https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine) is a well-known and widely used PGM for learning probabilistic distributions over binary data. We demonstrate how we can easily implement [perturb-and-max-product (PMP)](https://proceedings.neurips.cc/paper/2021/hash/07b1c04a30f798b5506c1ec5acfb9031-Abstract.html) sampling from an RBM trained on MNIST digits using PGMax. PMP is a recently proposed method for approximately sampling from a PGM by computing the maximum-a-posteriori (MAP) configuration (using max-product LBP) of a perturbed version of the model.\n",
        "\n",
        "We start by making some necessary imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hDkkNCKtAAu"
      },
      "outputs": [],
      "source": [
        "# # Uncomment this block if running on colab.research.google.com\n",
        "# !git clone https://github.com/deepmind/PGMax.git\n",
        "# %cd PGMax\n",
        "# !pip install -r requirements.txt\n",
        "# !python setup.py develop\n",
        "# !wget https://raw.githubusercontent.com/deepmind/PGMax/main/examples/example_data/rbm_mnist.npz\n",
        "# !mkdir example_data\n",
        "# !mv rbm_mnist.npz  example_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LILn6smVeBWP"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import functools\n",
        "\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "############\n",
        "# Load PGMax\n",
        "from pgmax import fgraph, fgroup, infer, vgroup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04DzBht7ppuG"
      },
      "source": [
        "The [`pgmax.fgraph`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgraph.html#module-pgmax.fgraph) module contains classes for specifying factor graphs, the [`pgmax.vgroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.vgroup.html#module-pgmax.vgroup) module contains classes for specifying groups of variables, the [`pgmax.fgroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.html#module-pgmax.fgroup) module contains classes for specifying groups of factors and the [`pgmax.infer`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.infer.html#module-pgmax.infer) module contains functions to perform LBP.\n",
        "\n",
        "We next load the RBM trained in Sec. 5.5 of the [PMP paper](https://proceedings.neurips.cc/paper/2021/hash/07b1c04a30f798b5506c1ec5acfb9031-Abstract.html) which has been trained on MNIST digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peLW-xjYeBur"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "folder_name = \"example_data/\"\n",
        "params = np.load(open(folder_name + \"rbm_mnist.npz\", 'rb'), allow_pickle=True)\n",
        "bv = params[\"bv\"]\n",
        "bh = params[\"bh\"]\n",
        "W = params[\"W\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W7C96g2vp-k"
      },
      "source": [
        "We can then initialize the factor graph for the RBM with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XxdeH0puB6F"
      },
      "outputs": [],
      "source": [
        "# Initialize factor graph\n",
        "hidden_variables = vgroup.NDVarArray(num_states=2, shape=bh.shape)\n",
        "visible_variables = vgroup.NDVarArray(num_states=2, shape=bv.shape)\n",
        "fg = fgraph.FactorGraph(variable_groups=[hidden_variables, visible_variables])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D4t9vPpvvjD"
      },
      "source": [
        "[`NDVarArray`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.vgroup.varray.NDVarArray.html#pgmax.vgroup.varray.NDVarArray) is a convenient class for specifying a group of variables living on a multidimensional grid with possibly different number of states: this class shares some similarities with [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html). The [`FactorGraph`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgraph.fgraph.FactorGraph.html#pgmax.fgraph.fgraph.FactorGraph) `fg` is initialized with a set of variables, which can be either a single [`VarGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.vgroup.vgroup.VarGroup.html#pgmax.vgroup.vgroup.VarGroup) (e.g. an [`NDVarArray`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.vgroup.varray.NDVarArray.html#pgmax.vgroup.varray.NDVarArray)), or a list of [`VarGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.vgroup.vgroup.VarGroup.html#pgmax.vgroup.vgroup.VarGroup)s. Once initialized, the set of variables in `fg` is fixed and cannot be changed.\n",
        "\n",
        "After initialization, `fg` does not have any factors. PGMax supports imperatively adding factors to a [`FactorGraph`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgraph.fgraph.FactorGraph.html#pgmax.fgraph.fgraph.FactorGraph). We efficiently add the unary and pairwise factors by grouping them using [`FactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.fgroup.FactorGroup.html#pgmax.fgroup.fgroup.FactorGroup)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gerj92Vvrk7"
      },
      "outputs": [],
      "source": [
        "# Create unary factors\n",
        "hidden_unaries = fgroup.EnumFactorGroup(\n",
        "    variables_for_factors=[[hidden_variables[ii]] for ii in range(bh.shape[0])],\n",
        "    factor_configs=np.arange(2)[:, None],\n",
        "    log_potentials=np.stack([np.zeros_like(bh), bh], axis=1),\n",
        ")\n",
        "visible_unaries = fgroup.EnumFactorGroup(\n",
        "    variables_for_factors=[[visible_variables[jj]] for jj in range(bv.shape[0])],\n",
        "    factor_configs=np.arange(2)[:, None],\n",
        "    log_potentials=np.stack([np.zeros_like(bv), bv], axis=1),\n",
        ")\n",
        "\n",
        "# Create pairwise factors\n",
        "log_potential_matrix = np.zeros(W.shape + (2, 2)).reshape((-1, 2, 2))\n",
        "log_potential_matrix[:, 1, 1] = W.ravel()\n",
        "\n",
        "variables_for_factors = [\n",
        "    [hidden_variables[ii], visible_variables[jj]]\n",
        "    for ii in range(bh.shape[0])\n",
        "    for jj in range(bv.shape[0])\n",
        "]\n",
        "pairwise_factors = fgroup.PairwiseFactorGroup(\n",
        "    variables_for_factors=variables_for_factors,\n",
        "    log_potential_matrix=log_potential_matrix,\n",
        ")\n",
        "\n",
        "# Add factors to the FactorGraph\n",
        "fg.add_factors([hidden_unaries, visible_unaries, pairwise_factors])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ3u-tYgv0Ew"
      },
      "source": [
        "PGMax implements convenient and computationally efficient [`FactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.fgroup.FactorGroup.html#pgmax.fgroup.fgroup.FactorGroup) for representing groups of similar factors. The code above makes use of [`EnumFactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.enum.EnumFactorGroup.html#pgmax.fgroup.enum.EnumFactorGroup) and [`PairwiseFactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.enum.PairwiseFactorGroup.html#pgmax.fgroup.enum.PairwiseFactorGroup).\n",
        "\n",
        "A [`FactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.fgroup.FactorGroup.html#pgmax.fgroup.fgroup.FactorGroup) takes as argument `variables_for_factors` which is a list of lists of the variables involved in the different factors, and additional arguments specific to each [`FactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.fgroup.FactorGroup.html#pgmax.fgroup.fgroup.FactorGroup) (e.g. `factor_configs` and `log_potential_matrix` here).\n",
        "\n",
        "In this example, since we construct `fg` with variables `hidden_variables` and `visible_variables`, which are both [`NDVarArray`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.vgroup.varray.NDVarArray.html#pgmax.vgroup.varray.NDVarArray)s, we can refer to the `ii`th hidden variable as `hidden_variables[ii]` and the `jj`th visible variable as `visible_variables[jj]`.\n",
        "\n",
        "An alternative way of creating the above factors is to add them iteratively without building the [`FactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.fgroup.FactorGroup.html#pgmax.fgroup.fgroup.FactorGroup)s as below. This approach is not recommended as it can be much slower than using [`FactorGroup`](https://pgmax.readthedocs.io/en/latest/_autosummary/pgmax.fgroup.fgroup.FactorGroup.html#pgmax.fgroup.fgroup.FactorGroup)s.\n",
        "\n",
        "~~~python\n",
        "from pgmax import factor\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Add unary factors\n",
        "for ii in range(bh.shape[0]):\n",
        "    unary_factor = factor.EnumFactor(\n",
        "        variables=[hidden_variables[ii]],\n",
        "        factor_configs=np.arange(2)[:, None],\n",
        "        log_potentials=np.array([0, bh[ii]]),\n",
        "    )\n",
        "    fg.add_factors(unary_factor)\n",
        "\n",
        "for jj in range(bv.shape[0]):\n",
        "    unary_factor = factor.EnumFactor(\n",
        "        variables=[visible_variables[jj]],\n",
        "        factor_configs=np.arange(2)[:, None],\n",
        "        log_potentials=np.array([0, bv[jj]]),\n",
        "    )\n",
        "    fg.add_factors(unary_factor)\n",
        "\n",
        "# Add pairwise factors\n",
        "factor_configs = np.array(list(itertools.product(np.arange(2), repeat=2)))\n",
        "for ii in tqdm(range(bh.shape[0])):\n",
        "    for jj in range(bv.shape[0]):\n",
        "        pairwise_factor = factor.EnumFactor(\n",
        "            variables=[hidden_variables[ii], visible_variables[jj]],\n",
        "            factor_configs=factor_configs,\n",
        "            log_potentials=np.array([0, 0, 0, W[ii, jj]]),\n",
        "        )\n",
        "        fg.add_factors(pairwise_factor)\n",
        "~~~\n",
        "\n",
        "Once we have added the factors, we can run max-product LBP and get MAP decoding by\n",
        "~~~python\n",
        "bp = infer.BP(fg.bp_state, temperature=0.0)\n",
        "bp_arrays = bp.run_bp(bp.init(), num_iters=100, damping=0.5)\n",
        "beliefs = bp.get_beliefs(bp_arrays)\n",
        "map_states = infer.decode_map_states(beliefs)\n",
        "~~~\n",
        "and run sum-product LBP and get estimated marginals by\n",
        "~~~python\n",
        "bp = infer.BP(fg.bp_state, temperature=1.0)\n",
        "bp_arrays = bp.run_bp(bp.init(), num_iters=100, damping=0.5)\n",
        "beliefs = bp.get_beliefs(bp_arrays)\n",
        "marginals = infer.get_marginals(beliefs)\n",
        "~~~\n",
        "More generally, PGMax implements LBP with temperature, with `temperature=0.0` and `temperature=1.0` corresponding to the commonly used max/sum-product LBP respectively.\n",
        "\n",
        "Now we are ready to demonstrate PMP sampling from RBM. PMP perturbs the model with [Gumbel](https://numpy.org/doc/stable/reference/random/generated/numpy.random.gumbel.html) unary potentials, and draws a sample from the RBM as the MAP decoding from running max-product LBP on the perturbed model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlpJouBKvxb_"
      },
      "outputs": [],
      "source": [
        "bp = infer.BP(fg.bp_state, temperature=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pW25Wxp083z"
      },
      "outputs": [],
      "source": [
        "bp_arrays = bp.init(\n",
        "    evidence_updates={\n",
        "        hidden_variables: np.random.gumbel(size=(bh.shape[0], 2)),\n",
        "        visible_variables: np.random.gumbel(size=(bv.shape[0], 2)),\n",
        "    }\n",
        ")\n",
        "bp_arrays = bp.run_bp(bp_arrays, num_iters=100, damping=0.5)\n",
        "beliefs = bp.get_beliefs(bp_arrays)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3qQmcVc1AVF"
      },
      "source": [
        "Here we use the `evidence_updates` argument of `bp.init` to perturb the model with Gumbel unary potentials. In general, `evidence_updates` can be used to incorporate evidence in the form of externally applied unary potentials in PGM inference.\n",
        "\n",
        "Visualizing the MAP decoding, we see that we have sampled an MNIST digit!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD6flvbP0-Gf"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "ax.imshow(\n",
        "    infer.decode_map_states(beliefs)[visible_variables].copy().reshape((28, 28)),\n",
        "    cmap=\"gray\",\n",
        ")\n",
        "ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOcR0GQr1Dz_"
      },
      "source": [
        "PGMax adopts a functional interface for implementing LBP: running LBP in PGMax starts with\n",
        "~~~python\n",
        "bp = infer.BP(fg.bp_state, temperature=T)\n",
        "~~~\n",
        "where the arguments of `bp` are several useful functions to run LBP. In particular, `bp.init`, `bp.run_bp`, `bp.get_beliefs` are pure functions with no side-effects. This design choice means that we can easily apply JAX transformations like `jit`/`vmap`/`grad`, etc., to these functions, and additionally allows PGMax to seamlessly interact with other packages in the rapidly growing JAX ecosystem (see [here](https://deepmind.com/blog/article/using-jax-to-accelerate-our-research) and [here](https://github.com/n2cholas/awesome-jax)).\n",
        "\n",
        "As an example of applying `jax.vmap` to `bp.init`/`bp.run_bp`/`bp.get_beliefs` to process a batch of samples/models in parallel, instead of drawing one sample at a time as above, we can draw a batch of samples in parallel as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kY3blQHS1BzG"
      },
      "outputs": [],
      "source": [
        "n_samples = 10\n",
        "bp_arrays = jax.vmap(bp.init, in_axes=0, out_axes=0)(\n",
        "    evidence_updates={\n",
        "        hidden_variables: np.random.gumbel(size=(n_samples, bh.shape[0], 2)),\n",
        "        visible_variables: np.random.gumbel(size=(n_samples, bv.shape[0], 2)),\n",
        "    },\n",
        ")\n",
        "bp_arrays = jax.vmap(\n",
        "    functools.partial(bp.run_bp, num_iters=100, damping=0.5),\n",
        "    in_axes=0,\n",
        "    out_axes=0,\n",
        ")(bp_arrays)\n",
        "\n",
        "beliefs = jax.vmap(bp.get_beliefs, in_axes=0, out_axes=0)(bp_arrays)\n",
        "map_states = infer.decode_map_states(beliefs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY8cS4CI1JiB"
      },
      "source": [
        "Visualizing the MAP decodings, we see that we have sampled 10 MNIST digits in parallel!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GA0FjuwZ1GDW"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 5, figsize=(20, 8))\n",
        "for ii in range(10):\n",
        "    ax[np.unravel_index(ii, (2, 5))].imshow(\n",
        "        map_states[visible_variables][ii].copy().reshape((28, 28)), cmap=\"gray\"\n",
        "    )\n",
        "    ax[np.unravel_index(ii, (2, 5))].axis(\"off\")\n",
        "\n",
        "fig.tight_layout()"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}
